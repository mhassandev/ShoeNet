{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')#GTK', 'GTKAgg', 'GTKCairo', 'GTK3Agg', 'GTK3Cairo', 'MacOSX', 'nbAgg', 'Qt4Agg', 'Qt4Cairo', \n",
    "#'Qt5Agg', 'Qt5Cairo', 'TkAgg', 'TkCairo', 'WebAgg', 'WX', 'WXAgg', 'WXCairo', 'agg', 'cairo', 'gdk', 'pdf', 'pgf', \n",
    "#'ps', 'svg', 'template'\n",
    "import matplotlib.pyplot as plt\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from pandas import read_excel\n",
    "import xlrd\n",
    "import math\n",
    "import concurrent.futures\n",
    "from skimage.io import imread\n",
    "import os.path\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d, upsample_2d,avg_pool_2d,grouped_conv_2d , conv_2d_transpose, batch_normalization, atrous_conv_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from tflearn.layers.normalization import batch_normalization\n",
    "from tflearn.layers.normalization import local_response_normalization#\n",
    "#from tflearn.optimizers import sgd, rmsprop, adadelta, adagrad, Adam\n",
    "from os import listdir\n",
    "input_data = tflearn.input_data\n",
    "fc = tflearn.fully_connected\n",
    "bn = tflearn.batch_normalization\n",
    "activation = tflearn.activation\n",
    "merge = tflearn.merge\n",
    "regression = tflearn.regression\n",
    "DNN = tflearn.DNN\n",
    "from sys import exit\n",
    "import sys\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread,imshow\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import label\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "input_data = tflearn.input_data\n",
    "fc = tflearn.fully_connected\n",
    "bn = tflearn.batch_normalization\n",
    "activation = tflearn.activation\n",
    "merge = tflearn.merge\n",
    "regression = tflearn.regression\n",
    "DNN = tflearn.DNN\n",
    "from sys import exit\n",
    "import sys\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as sk\n",
    "import scipy.ndimage as nd\n",
    "import skimage as sk\n",
    "import scipy.ndimage as nd\n",
    "#functions used for augmentation\n",
    "def img_rotate(imgr):\n",
    "    imgr=nd.rotate(imgr,8)\n",
    "    imgresize=cv2.resize(imgr, (224,224))\n",
    "    return(imgresize)\n",
    "def img_crop(img):\n",
    "    new_img=cv2.resize(img,(224,224,), interpolation = cv2.INTER_LANCZOS4)\n",
    "    new_img=new_img[8:216,8:216]\n",
    "    new_img=cv2.resize(img,(224,224,), interpolation = cv2.INTER_CUBIC)\n",
    "    return(new_img)\n",
    "def img_blur(img):\n",
    "    nimg=blurImg = cv2.blur(img,(5,5))\n",
    "    return(nimg)\n",
    "#////////////////////////////////flip image//////////////////////////////////\n",
    "def img_flip_ltr(imgf):\n",
    "    imgf=cv2.flip(imgf,1)\n",
    "    imgf=cv2.resize(imgf, (224,224), interpolation = cv2.INTER_CUBIC)\n",
    "    return(imgf)\n",
    "def img_noise(imgn):\n",
    "    return(cv2.resize(sk.util.random_noise(imgn, mode='gaussian', seed=None, clip=True), (224,224),interpolation = cv2.INTER_LANCZOS4))\n",
    "def img_flip_up(imgf):\n",
    "    imgf=cv2.flip(imgf,0)\n",
    "    imgf=np.array(imgf)\n",
    "    imgf=cv2.resize(imgf, (224,224))\n",
    "    return(imgf)\n",
    "def norm_image_return(imgn):\n",
    "    imgn=cv2.resize(imgn,(224,224))\n",
    "    return(imgn)\n",
    "import skimage\n",
    "def img_noise0(imgn):\n",
    "    return(cv2.resize(sk.util.random_noise(imgn, mode='s&p', seed=None, clip=True), (224,224), interpolation = cv2.INTER_CUBIC))\n",
    "#guassain,localvar, poisson, salt, pepper, s&p,speckle\n",
    "def img_noise1(imgn):\n",
    "    return(cv2.resize(sk.util.random_noise(imgn, mode='localvar', seed=None,var=1, clip=True), (224,224),interpolation = cv2.INTER_CUBIC))\n",
    "import skimage\n",
    "def cimage(img):\n",
    "    cimg=skimage.color.rgb2gray(img)\n",
    "    cimg=cv2.resize(cimg, (112,224), interpolation = cv2.INTER_CUBIC)\n",
    "    return(cimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "def tcimage(img):\n",
    "    cimg=skimage.color.rgb2gray(img)\n",
    "    cimg=cv2.resize(cimg, (112,224), interpolation = cv2.INTER_CUBIC)\n",
    "    return(cimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading gender dataset\n",
    "total_male_femal='path of gender dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating male and female\n",
    "male_list=[]\n",
    "female_list=[]\n",
    "for i in total_male_femal:\n",
    "    if i[3]==0:\n",
    "        male_list.append([cimage(i[0]),cimage(i[1]),i[2]])\n",
    "    elif i[3]==1:\n",
    "        female_list.append([cimage(i[0]),cimage(i[1]),i[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting lists into numpy array\n",
    "male_list=np.array(male_list)\n",
    "female_list=np.array(female_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mrging male and female into a single list of array\n",
    "tr_total=np.concatenate([tr_male,tr_femal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr_X is the list of shoeprints for male and female shoeprints\n",
    "#tr_Y is the list for the corresponding label in for gender i.e. [1,0] is for male , [0,1] for female\n",
    "tr_X=[cimage(i[0]) for i in tr_total]\n",
    "tr_Y=[i[1] for i in tr_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing for training \n",
    "tr_X=np.reshape(np.array(tr_X),(-1,224,224,1))\n",
    "tr_Y=np.reshape(tr_Y,(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the required packages\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tflearn\n",
    "import tflearn.activations as activations\n",
    "# Data loading and preprocessing\n",
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "from tflearn.activations import relu\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.conv import avg_pool_2d, conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import dropout, flatten, fully_connected, input_data\n",
    "from tflearn.layers.merge_ops import merge\n",
    "from tflearn.layers.normalization import batch_normalization\n",
    "from tflearn.utils import repeat\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.losses as tf_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for runtime augmentation\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "#img_aug1.add_random_flip_updown()\n",
    "img_aug.add_random_rotation(max_angle=8.)\n",
    "#img_aug.add_random_90degrees_rotation(rotations=[0,1,2,3])\n",
    "img_aug.add_random_blur(sigma_max=4.0)\n",
    "img_aug.add_random_crop((224,224), 8)\n",
    "img_prep=tflearn.ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()# img_prep.add_featurewise_zero_cneter(mean=[0.4,0.4,0.4])\n",
    "img_prep.add_featurewise_stdnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ShoeNet structure for gender classification\n",
    "network_in = input_data(shape=[None, 224, 224, 1], data_preprocessing=img_prep, data_augmentation=img_aug, name='Input1')\n",
    "network_in = tflearn.batch_normalization(network_in)\n",
    "network_in = tflearn.activations.relu(network_in)\n",
    "network3 = conv_2d(network_in, 32, 3, activation='relu')\n",
    "network3 = conv_2d(network3, 32, 3, activation='relu')\n",
    "network3a = conv_2d(network3, 32, 3, activation='relu')\n",
    "\n",
    "network1 = tflearn.batch_normalization(network3a)\n",
    "network1a = tflearn.activations.relu(network1)\n",
    "networktf = max_pool_2d(network1a, 2)#downsample by 2---112*112\n",
    "attension32=max_pool_2d(network_in,4)\n",
    "attension32=upsample_2d(attension32,2)\n",
    "attension32f=conv_2d(attension32,32,1)\n",
    "network32t = merge([networktf,attension32f], mode='elemwise_sum', axis=3)\n",
    "\n",
    "network64 = conv_2d(network32t, 64, 3, activation='relu')\n",
    "network64 = conv_2d(network64, 64, 3, activation='relu')\n",
    "network64 = conv_2d(network64, 64, 3, activation='relu')\n",
    "network64f = max_pool_2d(network64, 2)#downsample by 2---56*56\n",
    "attension64=max_pool_2d(network32t,4)\n",
    "attension64=upsample_2d(attension64,2)\n",
    "attension64f=conv_2d(attension64,64,1)\n",
    "network64t = merge([network64f,attension64f], mode='elemwise_sum', axis=3)\n",
    "\n",
    "\n",
    "network64a = conv_2d(network3a, 32, 1, activation='relu')\n",
    "network64a = max_pool_2d(network64a, 4)\n",
    "network64c = merge([network64t,network64a], mode='concat', axis=3)\n",
    "network64c = tflearn.batch_normalization(network64c)\n",
    "network64d = tflearn.activations.relu(network64c)\n",
    "\n",
    "network128 = conv_2d(network64d, 128, 3, activation='relu')\n",
    "network128 = conv_2d(network128, 128, 3, activation='relu')\n",
    "network128 = conv_2d(network128, 128, 3, activation='relu')\n",
    "network128f = max_pool_2d(network128, 2)#downsample by 2-----28*28\n",
    "attension128=max_pool_2d(network64d,4)\n",
    "attension128=upsample_2d(attension128,2)\n",
    "attension128f=conv_2d(attension128,128,1)\n",
    "network128t = merge([network128f,attension128f], mode='elemwise_sum', axis=3)\n",
    "\n",
    "\n",
    "network128a = conv_2d(network3a, 32, 1, activation='relu')\n",
    "network128a = max_pool_2d(network128a, 8)\n",
    "network128b = conv_2d(network64d, 32, 1, activation='relu')\n",
    "network128b = max_pool_2d(network128b, 2)#downsample by 2\n",
    "network128c= merge([network128t, network128a,network128b], mode='concat', axis=3)\n",
    "network128c = tflearn.batch_normalization(network128c)\n",
    "network128c = tflearn.activations.relu(network128c)\n",
    "\n",
    "network256 = conv_2d(network128c, 256, 3, activation='relu')\n",
    "network256 = conv_2d(network256, 256, 3, activation='relu')\n",
    "network256 = conv_2d(network256, 256, 3, activation='relu')\n",
    "network256f = max_pool_2d(network256, 2)#downsample by 2-----14*14\n",
    "attension256=max_pool_2d(network128c,4)\n",
    "attension256=upsample_2d(attension256,2)\n",
    "attension256f=conv_2d(attension256,256,1)\n",
    "network256t = merge([network256f,attension256f], mode='elemwise_sum', axis=3)\n",
    "\n",
    "network256a = conv_2d(network3a, 32, 1, activation='relu')\n",
    "network256a = max_pool_2d(network256a, 16)\n",
    "network256d = conv_2d(network64d, 32, 1, activation='relu')\n",
    "network256d = max_pool_2d(network256d, 4)\n",
    "network256e = conv_2d(network128c, 32, 1, activation='relu')\n",
    "network256e = max_pool_2d(network256e, 2)#downsample by 2\n",
    "network256c= merge([network256t, network256a,network256d,network256e], mode='concat', axis=3)\n",
    "network256c = tflearn.batch_normalization(network256c)\n",
    "network256c = tflearn.activations.relu(network256c)\n",
    "\n",
    "network512 = conv_2d(network256c, 512, 3, activation='relu')\n",
    "network512 = conv_2d(network512, 512, 3, activation='relu')\n",
    "network512 = conv_2d(network512, 512, 3, activation='relu')\n",
    "network512f = max_pool_2d(network512, 2)#downsample by 2---7*7\n",
    "attension512=max_pool_2d(network256c,2)\n",
    "attension512f=conv_2d(attension512,512, 1)\n",
    "network512t = merge([network512f,attension512f], mode='elemwise_sum', axis=3)\n",
    "\n",
    "network512a = conv_2d(network3a, 32, 1, activation='relu')\n",
    "network512a = max_pool_2d(network512a, 32)\n",
    "network512d = conv_2d(network64d, 32, 1, activation='relu')\n",
    "network512d = max_pool_2d(network512d, 8)\n",
    "network512e = conv_2d(network128c, 32, 1, activation='relu')\n",
    "network512e = max_pool_2d(network512e, 4)\n",
    "network512g = conv_2d(network256c, 32, 1, activation='relu')\n",
    "network512g = max_pool_2d(network512g, 2)#downsample by 2\n",
    "network512cc= merge([network512t, network512a,network512d,network512e,network512g], mode='concat', axis=3)\n",
    "\n",
    "network512c = tflearn.batch_normalization(network512cc)\n",
    "network512c = tflearn.activations.relu(network512c)\n",
    "\n",
    "network512c = fully_connected(network512cc, 512, activation='relu')\n",
    "network512c = dropout(network512c, 0.6)\n",
    "network = fully_connected(network512c, 384, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 256, activation='relu', regularizer='L2', weight_decay=0.001)\n",
    "network = dropout(network, 0.5)\n",
    "networko = fully_connected(network, 2, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam and SGD optimzers\n",
    "sgd=tflearn.optimizers.SGD(learning_rate=0.0001, lr_decay=0.98, decay_step=1000)\n",
    "adam=tflearn.optimizers.Adam(learning_rate=0.00001, beta1=0.999, beta2=0.9999, epsilon=1e-09, use_locking=False, name='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper-parameters including optimizer(adam), objective function(categorical crossentropy), accuracy metric(accuracy),\n",
    "#and learning rate(0.00001)\n",
    "convnet = regression(\n",
    "    networko, optimizer=adam,loss='categorical_crossentropy', \n",
    "    metric='accuracy' ,name='targets', learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep neural netowrk, with tensorbord verbose(0, for best visualization use 3), tnesor board directory\n",
    "modelb = tflearn.DNN(convnet, tensorboard_verbose=0,tensorboard_dir='/directory_path/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, mean_absolute_error\n",
    "from random import randint\n",
    "import collections\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn \n",
    "from pandas import DataFrame\n",
    "#from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training ShoeNet for genter classification\n",
    "#input images/shoeprints\n",
    "#lables for male and female\n",
    "#no of epoch\n",
    "#valiation set size(10% of training smaples)\n",
    "#snapshotp step\n",
    "#input size 56\n",
    "#enable shuffling\n",
    "#any model id\n",
    "modelb.fit({'Input1':tr_X}, {'targets':tr_Y}, n_epoch=no_of_epoch, validation_set=0.1, snapshot_step=1000, show_metric=True,\n",
    "           batch_size=56,shuffle=True, run_id='model_ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
